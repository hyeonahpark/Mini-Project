import streamlit as st
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import ChatMessage
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ë¹… 3 ìƒìœ„ë‰´ìŠ¤ ìš”ì•½", page_icon="ğŸ¤–", layout="centered")

# CSS ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
    <style>
    /* ì‚¬ìš©ì ë§í’ì„  ìŠ¤íƒ€ì¼ */
    .user-bubble {
        background-color: #071C6D;  /* íŒŒë€ìƒ‰ ë§í’ì„  */
        color: white;
        padding: 10px;
        border-radius: 20px;
        margin: 10px;
        width: fit-content; /* í…ìŠ¤íŠ¸ í¬ê¸°ì— ë§ê²Œ ë§í’ì„  ë„ˆë¹„ ì¡°ì • */
        margin-left: auto;  /* ì˜¤ë¥¸ìª½ ì •ë ¬ */
        text-align: right;
    }
    /* AI ë§í’ì„  ìŠ¤íƒ€ì¼ */
    .ai-bubble {
        background-color: #FFFFFF;  /* íšŒìƒ‰ ë§í’ì„  */
        color: black;
        padding: 10px;
        border-radius: 20px;
        margin: 10px;
        width: fit-content; /* í…ìŠ¤íŠ¸ í¬ê¸°ì— ë§ê²Œ ë§í’ì„  ë„ˆë¹„ ì¡°ì • */
        margin-right: auto;  /* ì™¼ìª½ ì •ë ¬ */
    }
    /* ì…ë ¥ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ */
    .input-box {
        position: fixed;
        bottom: 0;
        width: 100%;
        background-color: #CFE1EB;
        border: 1px solid #ccc;
        border-radius: 10px;
        padding: 10px;
        margin-bottom: 20px;
    }

    /* ì „ì²´ í˜ì´ì§€ ë°°ê²½ ìƒ‰ìƒ */
    html, body, [data-testid="stAppViewContainer"] {
        background-color: #CFE1EB;
    }

    /* ë©”ì¸ ë‚´ìš© ì»¨í…Œì´ë„ˆ ë°°ê²½ ìƒ‰ìƒ */
    [data-testid="stHeader"], [data-testid="stToolbar"] {
        background-color: #CFE1EB;
    }

    /* í•˜ë‹¨ ì—¬ë°± ë° ê³ ì • ìš”ì†Œ ë°°ê²½ ìƒ‰ìƒ */
    footer {
        background-color: #CFE1EB;
        position: fixed;
        bottom: 0;
        width: 100%;
        height: 50px;
    }

    /* í•˜ë‹¨ í‘¸í„°ì˜ í…ìŠ¤íŠ¸ ìˆ¨ê¹€ (í•„ìš”ì‹œ) */
    footer:after {
        content: '';
        display: block;
        position: fixed;
        bottom: 0;
        width: 100%;
        height: 30px;
        background-color: #CFE1EB;
    }

    </style>
""", unsafe_allow_html=True)



st.markdown("<h1 style='text-align: center;'>ğŸ“° ë¹… 3 ìƒìœ„ë‰´ìŠ¤ ìš”ì•½</h1>", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœì—ì„œ ëŒ€í™” ë‚´ìš©ì´ ì—†ì„ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ëŒ€í™” ë‚´ì—­ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
def print_history():
    for msg in st.session_state["messages"]:
        if msg.role == "user":
            st.markdown(f"<div class='user-bubble'>{msg.content}</div>", unsafe_allow_html=True)
        else:
            st.markdown(f"<div class='ai-bubble'>{msg.content}</div>", unsafe_allow_html=True)

# ëŒ€í™” ë‚´ì—­ì„ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜
def add_history(role, content):
    st.session_state["messages"].append(ChatMessage(role=role, content=content))  # 'user' ë˜ëŠ” 'ai' ë©”ì‹œì§€ êµ¬ë¶„

# ì²´ì¸ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (í”„ë¡¬í”„íŠ¸, ëª¨ë¸ ì—°ê²°)
def create_chain(prompt, model):
    chain = prompt | ChatOpenAI(model_name=model, api_key="my_key") | StrOutputParser()  # OpenAI APIì™€ íŒŒì‹± ì²´ì¸ ìƒì„±
    return chain

# ì‚¬ì´ë“œë°”ì— ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ê³¼ í”„ë¡¬í”„íŠ¸ ì„¤ì • ì¸í„°í˜ì´ìŠ¤ë¥¼ ì¶”ê°€
with st.sidebar:
    st.markdown("<h2 style='color: #1e272e;'>Settings</h2>", unsafe_allow_html=True)
    clear_btn = st.button("ëŒ€í™”ë‚´ìš© ì´ˆê¸°í™”")

    # í”„ë¡¬í”„íŠ¸ ì„¤ì • UI
    prompt = """ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”."""
    user_text_prompt = st.text_area("í”„ë¡¬í”„íŠ¸", value=prompt)
    user_text_apply_btn = st.button("í”„ë¡¬í”„íŠ¸ ì ìš©", key="apply1")

    # í”„ë¡¬í”„íŠ¸ ì ìš© ë¡œì§
    if user_text_apply_btn:
        st.markdown("<div style='color: green;'>âœ… í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤</div>", unsafe_allow_html=True)
        prompt_template = user_text_prompt + "\n\n#Question:\n{question}\n\n#Answer:"
        prompt = PromptTemplate.from_template(prompt_template)
        st.session_state["chain"] = create_chain(prompt, "gpt-3.5-turbo")  # ìˆ˜ì •ëœ í”„ë¡¬í”„íŠ¸ëŠ” PromptTemplateì„ í†µí•´ í…œí”Œë¦¿í™”ë˜ê³ , AI ëª¨ë¸ê³¼ì˜ ì²´ì¸ì´ ìƒˆë¡œ ìƒì„±

# ëŒ€í™”ë‚´ìš© ì´ˆê¸°í™” ë²„íŠ¼ì´ ëˆŒë¦¬ë©´ ì„¸ì…˜ ìƒíƒœì˜ ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”
if clear_btn:
    st.session_state["messages"].clear()

# ì´ì „ ëŒ€í™” ë‚´ì—­ ì¶œë ¥
print_history()

# ì„¸ì…˜ ìƒíƒœì— ì²´ì¸ì´ ì—†ë‹¤ë©´ ê¸°ë³¸ ì²´ì¸ì„ ìƒì„±
if "chain" not in st.session_state:
    prompt_template = user_text_prompt + "\n\n#Question:\n{question}\n\n#Answer:"  # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    prompt = PromptTemplate.from_template(prompt_template)  # í…œí”Œë¦¿ ìƒì„±
    st.session_state["chain"] = create_chain(prompt, "gpt-3.5-turbo")  # ì²´ì¸ ìƒì„± í›„ ì„¸ì…˜ì— ì €ì¥

# ì‚¬ìš©ìê°€ ì…ë ¥ì°½ì— ì§ˆë¬¸ì„ ì…ë ¥í–ˆì„ ë•Œ
if user_input := st.chat_input("Type your question here..."):
    add_history("user", user_input)  # ì…ë ¥ëœ ì§ˆë¬¸ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.markdown(f"<div class='user-bubble'>{user_input}</div>", unsafe_allow_html=True)  # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥

    # AIì˜ ë‹µë³€ ì²˜ë¦¬
    with st.chat_message("assistant"):
        chat_container = st.empty()  # ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œí•  ê³µê°„ ìƒì„±

        # AI ëª¨ë¸ì˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        stream_response = st.session_state["chain"].stream({"question": user_input})  # ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë°
        ai_answer = ""

        # ìŠ¤íŠ¸ë¦¬ë°ëœ AI ì‘ë‹µì„ ì°¨ë¡€ë¡œ í™”ë©´ì— ì¶œë ¥
        for chunk in stream_response:
            ai_answer += chunk  # ìŠ¤íŠ¸ë¦¬ë°ëœ ë‹µë³€ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
            chat_container.markdown(f"<div class='ai-bubble'>{ai_answer}</div>", unsafe_allow_html=True)  # ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— í‘œì‹œ

        # AI ì‘ë‹µì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        add_history("ai", ai_answer)
